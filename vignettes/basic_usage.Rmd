---
title: "Basic Usage"
output: 
  rmarkdown::html_vignette:
      toc: true
vignette: >
  %\VignetteIndexEntry{basic_usage}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  eval=TRUE,
  warning=FALSE,
  message=FALSE,
  comment = "#>",
  fig.width=6, fig.height=4
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

```{r, echo=FALSE}
# Load precooked results. See data-raw/generate_sysdata.R for details
hosp <- fiphde:::vd$hosp
prepped_hosp <- fiphde:::vd$prepped_hosp
prepped_hosp_tsibble <- fiphde:::vd$prepped_hosp_tsibble
hosp_fitfor <- fiphde:::vd$hosp_fitfor
formatted_list <- fiphde:::vd$formatted_list
```

```{r, eval=FALSE, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE}
devtools::build_vignettes()
devtools::install(build_vignettes = TRUE, upgrade = FALSE)
vignette("basic_usage", package="fiphde")
```

# Overview

The fiphde (**f**orecasting **i**nfluenza in support of **p**ublic **h**ealth **de**cision making) package provides utilities for forecasting influenza hospitalizations in the United States. fiphde provides functions for retrieval of hospitalization time series data from the HHS Protect system at [HealthData.gov](https://healthdata.gov/Hospital/COVID-19-Reported-Patient-Impact-and-Hospital-Capa/g62h-syeh), preparation of raw data for forecasting, fitting time series and count regression models to create probabilistic forecasts for influenza hospitalizations at state and national levels, visualizing and evaluating forecasts, and formatting forecasts for submission to [FluSight](https://www.cdc.gov/flu/weekly/flusight/index.html).

fiphde rhymes with "fifty," as in the 50 states in the US.

# Usage

The fiphde package retrieves current data from HHS and CDC APIs and fits models and forecasts using this data. This vignette uses data current to May 28, 2022 (MMWR epidemiological week 21 of 2022). Running the code here as written will produce different results depending on _when_ you run the code, as new data is constantly being added and historical data is constantly being revised.

To get started, first load the packages that are used in this vignette.

```{r setup,}
library(fiphde)
library(dplyr)
library(purrr)
library(readr)
library(ggplot2)
theme_set(theme_bw())
```

## Data retrieval

Prior to fitting any forecasts we need to first retrieve data from the [HealthData.gov COVID-19 Reported Patient Impact and Hospital Capacity by State Timeseries API](https://healthdata.gov/Hospital/COVID-19-Reported-Patient-Impact-and-Hospital-Capa/g62h-syeh). 

```{r, eval=FALSE}
hosp <- get_hdgov_hosp(limitcols = TRUE)
```

```{r}
hosp
```

## Time series forecasting

We will first fit a time series model, creating an ensemble model from ARIMA and exponential smoothing time series models. Time series modeling is based on the tidyverts (<https://tidyverts.org/>) collection of packages for tidy time series forecasting in R.

### Data preparation

FIrst let's prepare the data for a time series forecast. The `prep_hdgov_hosp` function call below will limit to states only (removes territories), removes any data from an incomplete epidemiological week (Sunday-Saturday), removes locations with little to no reported hospitalizations over the last month, and further removes Washington DC. Then the function summarizes total number of cases over each epidemiological week at each location. This function also adds in location FIPS codes, and joins in historical unweighted influenza-like illness (ILI) and hospitalizations mean and ranks. ILI data collected from [CDC ILINet](https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html), and historical flu hospitalization data collected from [CDC FluSurv-Net](https://www.cdc.gov/flu/weekly/influenza-hospitalization-surveillance.htm).

```{r, eval=FALSE}
# Prep data
prepped_hosp <-
  hosp %>%
  prep_hdgov_hosp(statesonly=TRUE, min_per_week = 0, remove_incomplete = TRUE) %>%
  dplyr::filter(abbreviation != "DC")
```

```{r}
prepped_hosp
```

Let's explore the data:

```{r}
prepped_hosp %>% 
  filter(abbreviation %in% c("US", "CA", "TX", "NY")) %>% 
  ggplot(aes(week_end, flu.admits)) + geom_line() + 
  facet_wrap(~abbreviation, scale="free_y")
```

What states had the highest admissions over the 2021-2022 flu season?

```{r}
prepped_hosp %>% 
  filter(abbreviation!="US") %>% 
  filter(week_start>="2021-07-01" & week_end<"2022-06-30") %>% 
  group_by(abbreviation) %>% 
  summarize(total.flu.admits=sum(flu.admits)) %>% 
  arrange(desc(total.flu.admits)) %>% 
  head(10) %>% 
  knitr::kable(caption="Top 10 states with highest flu hospitalizations in 2021-2022.")
```

Next let's turn this into a [tsibble](https://tsibble.tidyverts.org/). tsibble objects are tibbles with an _index_ variable describing the inherent ordering from past to present, and a _key_ that defines observational units over time. The `make_tsibble` function provides a convenience wrapper around `tsibble::as_tsibble` using the epidemiological week's Monday as the weekly index and the location as the key.  

```{r, eval=FALSE}
prepped_hosp_tsibble <- make_tsibble(prepped_hosp,
                                     epiyear = epiyear,
                                     epiweek=epiweek,
                                     key=location)
```

```{r}
prepped_hosp_tsibble
```


### Fit a model and forecast

Next, let's fit a time series model and create forecasts using the `ts_fit_forecast` function. This function takes a tsibble created as above, a forecast horizon in weeks, the name of the outcome variable to forecast, and optional covariates to use in the ARIMA model. 

Here we fit a nonseasonal ARIMA model with the nonseasonal autoregressive term (p) restricted to 1:2, order of integration for non-seasonal differencing restricted to 0:2, and the moving average restricted to 0 (see `?fable::ARIMA` for more information). The model also fits a non-seasonal exponential smoothing model (see `?fable::ETS` for details). In this example we do not fit an auto-regressive neural network model, but we could change `nnetar=NULL` to `nnetar="AR(P=1)"` to do so (see `?fable::nnetar` for details). We trim the data at January 1 2021 (hospitalization data prior to that date is sparse and not useful for learning). By setting `ensemble=TRUE` we create an ensemble model by averaging the ARIMA and exponential smoothing models. By setting `remove_null_models=TRUE` we catch models that did not converge to a solution and remove those from downstream processing.

```{r, eval=FALSE}
hosp_fitfor <- ts_fit_forecast(prepped_hosp_tsibble,
                               horizon=4L,
                               outcome="flu.admits",
                               trim_date = "2021-01-01",
                               covariates=c("hosp_rank", "ili_rank"), 
                               models=list(arima='PDQ(0, 0, 0) + pdq(1:2, 0:2, 0)',
                                           ets='season(method="N")',
                                           nnetar=NULL), 
                               ensemble=TRUE, 
                               remove_null_models=TRUE)
```

The function will output messages describing the ARIMA and ETS model formulas passed to `fable::ARIMA` and `fable::ETS`:

```
Trimming to 2021-01-01
ARIMA  formula: flu.admits ~ PDQ(0, 0, 0) + pdq(1:2, 0:2, 0) + hosp_rank + ili_rank
ETS    formula: flu.admits ~ season(method = "N")
```

After fitting the models, the function then forecasts the specified outcome to the specified number of weeks. Let's take a look at the object returned from this model fit + forecast. We see `$tsfit`, which gives us the ARIMA, ETS, and ensemble model fits as list columns, one row per location; `$tsfor` gives us the forecast for the next four weeks, one row per model per location (key in the tsibble); `$formulas` gives us the model formulas passed to fable modeling functions; and if any models failed to converge we would see those locations in `$nullmodels`.

```{r}
hosp_fitfor
```

Next, we can format the forecasts for [submission to FluSight](https://github.com/cdcepi/Flusight-forecast-data/blob/master/data-forecasts/README.md) using the `format_for_submission` function.

```{r, eval=FALSE}
formatted_list <- format_for_submission(hosp_fitfor$tsfor)
```

The list contains separate submission-ready tibbles, one element for each type of model fitted. 

```{r}
formatted_list
```

We can check to see if the submission is [valid](https://github.com/cdcepi/Flusight-forecast-data/blob/e1a2a05fa2bb065dfa80a7067c444394edde05e2/data-forecasts/README.md#Forecast-validation). Note that this will fail if the expected date of the target dates and current dates don't line up. You'll see a message noting _"The submission target end dates do not line up with expected Saturdays by horizon. Note if submission forecast date is not Sunday or Monday, then forecasts are assumed to to start the following week."_ If validation succeeds, the `$valid` element of the returned list will be `TRUE`, and `FALSE` if any validation checks fail.

```{r, eval=FALSE}
validate_forecast(formatted_list$ensemble)
```

Let's plot the forecast with the observed data using the `plot_forecast` function. Here we plot forecasts with the 50% prediction interval for US, New York (FIPS 36) and Florida (FIPS 12).

```{r}
plot_forecast(prepped_hosp, formatted_list$ensemble, loc="US", pi = .5)
plot_forecast(prepped_hosp, formatted_list$ensemble, loc="36", pi = .5)
plot_forecast(prepped_hosp, formatted_list$ensemble, loc="12", pi = .5)
```

Finally, we can pull out the ARIMA model parameters used for each location to save for posterity or retrospective analysis:

```{r}
hosp_fitfor$tsfit$arima %>% 
  map("fit") %>% 
  map_df("spec") %>% 
  mutate(location = hosp_fitfor$tsfit$location, .before = "p")
```

## Count regression forecasting

### ILI retrieval and prep

### Fit a model and forecast

### Advanced: parallelize forecasts over locations

## FIPHDE explorer Shiny app

```{r, eval=TRUE}
knitr::knit_exit()
```


<!-- Everything below is leftover from SAJ's previous start. -->

First, let's retrieve Influenza-like Illness (ILI) data from [CDC FluView](https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html). Note that `years` argument gets the *flu season* corresponding to the year. If you only get 2020-2021, you're getting the 2020-2021 and 2021-2022 flu season, meaning that you will *NOT* capture early 2020 data.

```{r, message = FALSE, eval=FALSE}
ilidat <- get_cdc_ili(region=c("national","state"), years=2019:lubridate::year(lubridate::today()))
```

Some states have missing ILI data so we pull from [CMU Delphi NowCast](https://delphi.cmu.edu/nowcast/) instead.

```{r, message = FALSE, eval=FALSE}
# Replace FluView data with NowCast data for Florida only
ilidat <- state_replace_ili_nowcast_all(ilidat, state="FL")

## Pull NowCast data for all states for a specified date
iliaug <- replace_ili_nowcast(ilidat, weeks_to_replace=1)
```

